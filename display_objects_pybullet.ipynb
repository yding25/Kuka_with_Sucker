{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yding25/Kuka_with_Sucker/blob/main/display_objects_pybullet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display all objects\n",
        "<img src=\"https://raw.githubusercontent.com/yding25/pic_share/master/utensil.jpeg\" height=\"300\" />\n",
        "\n",
        "Object library: <a href=\"https://github.com/yding25/URDF_models\"> URDF_models </a>"
      ],
      "metadata": {
        "id": "NG4PFheoKszr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "69dNNdQvBBJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download URDF models {display-mode: \"form\"}\n",
        "# !rm -rf /content/urdf_models/\n",
        "!git clone https://github.com/yding25/urdf_models.git"
      ],
      "metadata": {
        "id": "gQ_4cTZ5A_Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79LR00AYmlb6"
      },
      "source": [
        "#@title Import third-party packages {display-mode: \"form\"}\n",
        "!pip install pybullet imageio-ffmpeg\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pybullet\n",
        "import pybullet_data\n",
        "import cv2\n",
        "import imageio_ffmpeg\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils {display-mode: \"form\"}\n",
        "\n",
        "class Client():\n",
        "  def __init__(self):\n",
        "    pybullet.connect(pybullet.DIRECT) # pybullet.GUI for local GUI.\n",
        "    pybullet.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "    pybullet.setGravity(0, 0, -9.8)\n",
        "    \n",
        "    self.plane_id = pybullet.loadURDF(\"plane.urdf\")\n",
        "\n",
        "    # camera width and height\n",
        "    self.cam_width = 4800\n",
        "    self.cam_height = 4800\n",
        "\n",
        "  def render_image(self):\n",
        "    # camera parameters\n",
        "    cam_target_pos = [1.0, 0.0, 0.5]\n",
        "    cam_distance = 2.0\n",
        "    cam_yaw, cam_pitch, cam_roll = -90, -90, 0\n",
        "    cam_up, cam_up_axis_idx, cam_near_plane, cam_far_plane, cam_fov = [0, 0, 1], 2, 0.01, 100, 60\n",
        "    cam_view_matrix = pybullet.computeViewMatrixFromYawPitchRoll(cam_target_pos, cam_distance, cam_yaw, cam_pitch, cam_roll, cam_up_axis_idx)\n",
        "    cam_projection_matrix = pybullet.computeProjectionMatrixFOV(cam_fov, self.cam_width*1./self.cam_height, cam_near_plane, cam_far_plane)\n",
        "    znear, zfar = 0.01, 10.\n",
        "\n",
        "    # get raw data\n",
        "    _, _, color, depth, segment = pybullet.getCameraImage(\n",
        "        width=self.cam_width,\n",
        "        height=self.cam_height,\n",
        "        viewMatrix=cam_view_matrix,\n",
        "        projectionMatrix=cam_projection_matrix,\n",
        "        shadow=1,\n",
        "        flags=pybullet.ER_SEGMENTATION_MASK_OBJECT_AND_LINKINDEX,\n",
        "        renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
        "\n",
        "    # get color image.\n",
        "    color_image_size = (self.cam_width, self.cam_height, 4)\n",
        "    color = np.array(color, dtype=np.uint8).reshape(color_image_size)\n",
        "    color = color[:, :, :3]  # remove alpha channel\n",
        "\n",
        "    # get depth image.\n",
        "    depth_image_size = (self.cam_width, self.cam_height)\n",
        "    zbuffer = np.float32(depth).reshape(depth_image_size)\n",
        "    depth = (zfar + znear - (2 * zbuffer - 1) * (zfar - znear))\n",
        "    depth = (2 * znear * zfar) / depth\n",
        "\n",
        "    # get segment image.\n",
        "    segment = np.reshape(segment, [self.cam_width, self.cam_height]) * 1. / 255.\n",
        "    return color, depth, segment\n",
        "\n",
        "  def reset_video(self):\n",
        "    video = imageio_ffmpeg.write_frames('video.mp4', (self.cam_width, self.cam_height), fps=60)\n",
        "    video.send(None) # seed the video writer with a blank frame\n",
        "    return video\n",
        "\n",
        "  def render_video(self, video, image):\n",
        "    video.send(np.ascontiguousarray(image))\n",
        "    \n",
        "  def play_video(self):\n",
        "    mp4 = open('video.mp4', 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML('<video width=480 controls><source src=\"%s\" type=\"video/mp4\"></video>' % data_url)\n",
        "\n",
        "  def add_object(self, utensil_name, utensil_pose):\n",
        "    flags = pybullet.URDF_USE_INERTIA_FROM_FILE\n",
        "    utensil_id = pybullet.loadURDF(utensil_name, basePosition=utensil_pose[0], baseOrientation=utensil_pose[1], flags=flags)\n",
        "    return utensil_id\n",
        "  \n",
        "  def remove_object(self, utensil_id):\n",
        "    pybullet.removeBody(utensil_id)\n",
        "\n",
        "  def get_bounding_box(self, obj_id):\n",
        "    (min_x, min_y, min_z), (max_x, max_y, max_z)= pybullet.getAABB(obj_id)\n",
        "    return [min_x, min_y, min_z], [max_x, max_y, max_z]\n",
        "\n",
        "  def home_joints(self):\n",
        "    jointPositions = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "    for jointIndex in range(pybullet.getNumJoints(self.robot_id)):\n",
        "        pybullet.resetJointState(self.robot_id, jointIndex, jointPositions[jointIndex])\n",
        "        pybullet.setJointMotorControl2(self.robot_id, jointIndex, pybullet.POSITION_CONTROL, jointPositions[jointIndex], 0)\n",
        "\n",
        "  def disconnect(self):\n",
        "    pybullet.disconnect()\n",
        "  \n",
        "  def sample_pose(self):\n",
        "    # max_pose = [[1.5, 0.75, 0.6], [0, 0, 0, 1]]\n",
        "    # min_pose = [[0.5, -0.75, 0.6], [0, 0, 0, 1]]\n",
        "    pose_list = []\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, 0.75, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, 0.45, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, 0.15, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, -0.15, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, -0.45, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    for i in range(5):\n",
        "      temp = [[1.4 - 0.3 * i, -0.75, 0.2], [0, 0, 0, 1]]\n",
        "      pose_list.append(temp)\n",
        "    return pose_list"
      ],
      "metadata": {
        "id": "qvYPnvkUcUMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Environment"
      ],
      "metadata": {
        "id": "Ygo6za_hdGiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize env {display-mode: \"form\"}\n",
        "demo = Client()"
      ],
      "metadata": {
        "id": "SGiqjIsCnqrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add objects {display-mode: \"form\", vertical-output: true }\n",
        "path_urdf_models = '/content/urdf_models/'\n",
        "object_list = os.listdir(path_urdf_models)\n",
        "counter = 0\n",
        "utensil_list = []\n",
        "for object in object_list: # remove noise\n",
        "  if 'chair' in object:\n",
        "    utensil_list.append(object)\n",
        "utensil_list.sort()\n",
        "\n",
        "# get potential pose\n",
        "pose_list = demo.sample_pose()\n",
        "\n",
        "index = 0\n",
        "for object in utensil_list: # find path of object's urdf\n",
        "  print('object: {}'.format(object))\n",
        "  path_object = os.path.join(path_urdf_models, object)\n",
        "  for file in os.listdir(path_object):\n",
        "    if file.endswith('.urdf'):\n",
        "      path_object_urdf = os.path.join(path_object, file)\n",
        "      # print('path of object urdf: {}'.format(path_object_urdf))\n",
        "      # add object\n",
        "      utensil_name = path_object_urdf\n",
        "      utensil_pose = pose_list[index]\n",
        "      utensil_id = demo.add_object(path_object_urdf, utensil_pose)\n",
        "      index += 1"
      ],
      "metadata": {
        "id": "4AW4XFFpLsZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a00a8b7-e3b3-49d2-9517-25adab0182c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object: furniture_chair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title display object {display-mode: \"form\", vertical-output: true }\n",
        "rgb, depth, mask = demo.render_image()\n",
        "# plt.imshow(rgb)\n",
        "plt.imsave('furniture.jpeg', rgb)\n",
        "files.download('furniture.jpeg')\n",
        "demo.disconnect() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GuFbR1mV9_tp",
        "outputId": "880719f5-4427-46b9-f6d1-ad045acaf94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1c05f75-98f4-4268-833f-df8cf6afb875\", \"furniture.jpeg\", 487171)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}